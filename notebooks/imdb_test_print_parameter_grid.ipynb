{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PLOTTER OF THE RESULTS OF A GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from scipy.stats import t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/home/zhanna/bachelorarbeit/zbb/experiments/output_grid_search_10_12_23\"\n",
    "output_dir = \"/home/zhanna/bachelorarbeit/zbb/experiments/output_grid_search_final\"\n",
    "output_dir = \"/home/zhanna/bachelorarbeit/zbb/experiments/output_grid_search_000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    \"NaiveSA\",\n",
    "    \"AFinn\",\n",
    "    \"Vader\",\n",
    "    \"RandomForest\",\n",
    "    \"LogisticRegression\",\n",
    "    \"SVM\",\n",
    "    \"LSTM\",\n",
    "    \"RandomForestW2V\",\n",
    "    \"LogisticRegressionW2V\",\n",
    "    \"SVM_W2V\",\n",
    "    \"LSTM_W2V\",\n",
    "]\n",
    "\n",
    "model_name = model_names[0]\n",
    "file_name = os.path.join(output_dir, 'best_params_{}.json'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'rb') as f:\n",
    "    p = json.load(f)\n",
    "best_param = {}\n",
    "for k, v in p.items():\n",
    "    best_param[k] = [v]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      " & 0 \\\\\n",
      "\\midrule\n",
      "data_selector__dimension & reviews_no_stopwords \\\\\n",
      "data_selector__verbose & 1 \\\\\n",
      "naive_sa__tokenizer_name & split \\\\\n",
      "naive_sa__use_frequency & False \\\\\n",
      "naive_sa__verbose & 1 \\\\\n",
      "naive_sa__weigth_added_words & 2.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.transpose().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrlrrr}\n",
      "\\toprule\n",
      " & data_selector__dimension & data_selector__verbose & naive_sa__tokenizer_name & naive_sa__use_frequency & naive_sa__verbose & naive_sa__weigth_added_words \\\\\n",
      "\\midrule\n",
      "0 & reviews_no_stopwords & 1 & split & False & 1 & 2.000000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_selector__dimension reviews_no_stopwords\n",
      "data_selector__verbose 1\n",
      "naive_sa__tokenizer_name split\n",
      "naive_sa__use_frequency False\n",
      "naive_sa__verbose 1\n",
      "naive_sa__weigth_added_words 2.0\n"
     ]
    }
   ],
   "source": [
    "for k, v in p.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_best_parameters(model_name):\n",
    "    file_name = os.path.join(output_dir, 'best_params_{}.json'.format(model_name))\n",
    "    try:\n",
    "        with open(file_name, 'rb') as f:\n",
    "            p = json.load(f)\n",
    "    except Exception as e: \n",
    "        print(\" for model \", model_name, \": \", str(e))\n",
    "        return \"\"\n",
    "    best_param = {}\n",
    "    for k, v in p.items():\n",
    "        if k.find('verbose') >= 0: continue\n",
    "        best_param['\\\\texttt{' + k + '}'] = ['\\\\texttt{' + str(v) + '}']\n",
    "    df = pd.DataFrame(best_param)\n",
    "    google_from, google_to = \"/data/zibaldone/projects/ai/zbb//data//datasets/googleW2v/word2vec-google-news-300.gz\", \"word2vec-google-news-300.gz\"\n",
    "    google2_from, google2_to = \"/usr/src/myapp//data//datasets/googleW2v/word2vec-google-news-300.gz\", \"word2vec-google-news-300.gz\"\n",
    "    words_from, words_to = \"/usr/src/myapp//data//datasets/googleW2v/word2vec-google-news-300.gz\", \"word2vec-google-news-300.gz\"\n",
    "    return (\n",
    "        df.transpose()\n",
    "        .to_latex()\n",
    "            .replace('& 0 \\\\', '\\\\textbf{{{}}} & \\\\textbf{{Hyperparamter Wert}} \\\\'.format(model_name))\n",
    "            .replace('_', '\\\\_')\n",
    "            .replace(google_from, google_to)\n",
    "            .replace(google2_from, google2_to)\n",
    "            .replace(words_from, words_to)\n",
    "            )\n",
    "def print_all_best_parameters(models):\n",
    "    str = \"\"\n",
    "    for m in models:\n",
    "        s = print_best_parameters(m)\n",
    "        if len(s) == 0: continue\n",
    "        str += \"\\\\begin{table}[H]\\n\"\n",
    "        str += \"\\\\centering\\n\"\n",
    "        str += s\n",
    "        m = m.replace('_', '\\_')\n",
    "        str += \"\\\\caption[Hyperparameter für das Modell {}]{{Optimal ausgewählte Hyperparameter für das Modell {}}}\\n\".format(m, m)\n",
    "        str += \"\\\\end{table}\\n\\n\"\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " for model  SVM_W2V :  [Errno 2] No such file or directory: '/home/zhanna/bachelorarbeit/zbb/experiments/output_grid_search_000/best_params_SVM_W2V.json'\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      " \\textbf{NaiveSA} & \\textbf{Hyperparamter Wert} \\\\\n",
      "\\midrule\n",
      "\\texttt{data\\_selector\\_\\_dimension} & \\texttt{reviews\\_no\\_stopwords} \\\\\n",
      "\\texttt{naive\\_sa\\_\\_tokenizer\\_name} & \\texttt{split} \\\\\n",
      "\\texttt{naive\\_sa\\_\\_use\\_frequency} & \\texttt{False} \\\\\n",
      "\\texttt{naive\\_sa\\_\\_weigth\\_added\\_words} & \\texttt{2.0} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption[Hyperparameter für das Modell NaiveSA]{Optimal ausgewählte Hyperparameter für das Modell NaiveSA}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      " \\textbf{AFinn} & \\textbf{Hyperparamter Wert} \\\\\n",
      "\\midrule\n",
      "\\texttt{data\\_selector\\_\\_dimension} & \\texttt{reviews\\_no\\_punctuation} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption[Hyperparameter für das Modell AFinn]{Optimal ausgewählte Hyperparameter für das Modell AFinn}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      " \\textbf{Vader} & \\textbf{Hyperparamter Wert} \\\\\n",
      "\\midrule\n",
      "\\texttt{data\\_selector\\_\\_dimension} & \\texttt{reviews\\_no\\_punctuation} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption[Hyperparameter für das Modell Vader]{Optimal ausgewählte Hyperparameter für das Modell Vader}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      " \\textbf{RandomForest} & \\textbf{Hyperparamter Wert} \\\\\n",
      "\\midrule\n",
      "\\texttt{data\\_selector\\_\\_dimension} & \\texttt{reviews\\_no\\_stopwords} \\\\\n",
      "\\texttt{rndf\\_\\_criterion} & \\texttt{entropy} \\\\\n",
      "\\texttt{rndf\\_\\_n\\_jobs} & \\texttt{5} \\\\\n",
      "\\texttt{vect\\_\\_ngram\\_range} & \\texttt{[1, 2]} \\\\\n",
      "\\texttt{vect\\_\\_norm} & \\texttt{l2} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption[Hyperparameter für das Modell RandomForest]{Optimal ausgewählte Hyperparameter für das Modell RandomForest}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      " \\textbf{LogisticRegression} & \\textbf{Hyperparamter Wert} \\\\\n",
      "\\midrule\n",
      "\\texttt{clf\\_\\_C} & \\texttt{100.0} \\\\\n",
      "\\texttt{clf\\_\\_penalty} & \\texttt{l2} \\\\\n",
      "\\texttt{data\\_selector\\_\\_dimension} & \\texttt{reviews\\_no\\_punctuation} \\\\\n",
      "\\texttt{vect\\_\\_ngram\\_range} & \\texttt{[1, 2]} \\\\\n",
      "\\texttt{vect\\_\\_norm} & \\texttt{l2} \\\\\n",
      "\\texttt{vect\\_\\_stop\\_words} & \\texttt{None} \\\\\n",
      "\\texttt{vect\\_\\_tokenizer} & \\texttt{None} \\\\\n",
      "\\texttt{vect\\_\\_use\\_idf} & \\texttt{True} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption[Hyperparameter für das Modell LogisticRegression]{Optimal ausgewählte Hyperparameter für das Modell LogisticRegression}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      " \\textbf{SVM} & \\textbf{Hyperparamter Wert} \\\\\n",
      "\\midrule\n",
      "\\texttt{data\\_selector\\_\\_dimension} & \\texttt{reviews\\_no\\_stopwords} \\\\\n",
      "\\texttt{svm\\_\\_C} & \\texttt{10.0} \\\\\n",
      "\\texttt{svm\\_\\_kernel} & \\texttt{rbf} \\\\\n",
      "\\texttt{svm\\_\\_max\\_iter} & \\texttt{2000} \\\\\n",
      "\\texttt{vect\\_\\_ngram\\_range} & \\texttt{[1, 1]} \\\\\n",
      "\\texttt{vect\\_\\_stop\\_words} & \\texttt{None} \\\\\n",
      "\\texttt{vect\\_\\_tokenizer} & \\texttt{None} \\\\\n",
      "\\texttt{vect\\_\\_use\\_idf} & \\texttt{False} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption[Hyperparameter für das Modell SVM]{Optimal ausgewählte Hyperparameter für das Modell SVM}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      " \\textbf{LSTM} & \\textbf{Hyperparamter Wert} \\\\\n",
      "\\midrule\n",
      "\\texttt{data\\_selector\\_\\_dimension} & \\texttt{stamm\\_no\\_stop\\_punct} \\\\\n",
      "\\texttt{lstm\\_sa\\_\\_epoches} & \\texttt{5} \\\\\n",
      "\\texttt{vect\\_\\_max\\_features} & \\texttt{1000} \\\\\n",
      "\\texttt{vect\\_\\_norm} & \\texttt{l2} \\\\\n",
      "\\texttt{vect\\_\\_use\\_idf} & \\texttt{True} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption[Hyperparameter für das Modell LSTM]{Optimal ausgewählte Hyperparameter für das Modell LSTM}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      " \\textbf{RandomForestW2V} & \\textbf{Hyperparamter Wert} \\\\\n",
      "\\midrule\n",
      "\\texttt{data\\_selector\\_\\_dimension} & \\texttt{reviews\\_no\\_stopwords} \\\\\n",
      "\\texttt{rndf\\_\\_criterion} & \\texttt{entropy} \\\\\n",
      "\\texttt{rndf\\_\\_n\\_jobs} & \\texttt{5} \\\\\n",
      "\\texttt{vect\\_\\_model} & \\texttt{word2vec-google-news-300.gz} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption[Hyperparameter für das Modell RandomForestW2V]{Optimal ausgewählte Hyperparameter für das Modell RandomForestW2V}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      " \\textbf{LogisticRegressionW2V} & \\textbf{Hyperparamter Wert} \\\\\n",
      "\\midrule\n",
      "\\texttt{clf\\_\\_C} & \\texttt{100.0} \\\\\n",
      "\\texttt{clf\\_\\_penalty} & \\texttt{l2} \\\\\n",
      "\\texttt{data\\_selector\\_\\_dimension} & \\texttt{reviews\\_no\\_punctuation} \\\\\n",
      "\\texttt{vect\\_\\_model} & \\texttt{word2vec-google-news-300.gz} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption[Hyperparameter für das Modell LogisticRegressionW2V]{Optimal ausgewählte Hyperparameter für das Modell LogisticRegressionW2V}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      " \\textbf{LSTM\\_W2V} & \\textbf{Hyperparamter Wert} \\\\\n",
      "\\midrule\n",
      "\\texttt{data\\_selector\\_\\_dimension} & \\texttt{stamm\\_no\\_stop\\_punct} \\\\\n",
      "\\texttt{lstm\\_sa\\_\\_bidirectional} & \\texttt{True} \\\\\n",
      "\\texttt{lstm\\_sa\\_\\_epoches} & \\texttt{5} \\\\\n",
      "\\texttt{lstm\\_sa\\_\\_layer\\_1} & \\texttt{True} \\\\\n",
      "\\texttt{lstm\\_sa\\_\\_layer\\_1\\_activation} & \\texttt{relu} \\\\\n",
      "\\texttt{lstm\\_sa\\_\\_layer\\_1\\_size} & \\texttt{64} \\\\\n",
      "\\texttt{lstm\\_sa\\_\\_max\\_words} & \\texttt{300} \\\\\n",
      "\\texttt{lstm\\_sa\\_\\_model} & \\texttt{word2vec-google-news-300.gz} \\\\\n",
      "\\texttt{lstm\\_sa\\_\\_output\\_activation} & \\texttt{softmax} \\\\\n",
      "\\texttt{lstm\\_sa\\_\\_words} & \\texttt{/usr/src/myapp//data//datasets/all\\_words.csv} \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption[Hyperparameter für das Modell LSTM\\_W2V]{Optimal ausgewählte Hyperparameter für das Modell LSTM\\_W2V}\n",
      "\\end{table}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(print_all_best_parameters(model_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
